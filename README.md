# Stock Movement Prediction System

A machine learning system that predicts stock price movements by analyzing tweets using BERT embeddings and deep learning models (LSTM, GRU, Bidirectional).

## ğŸ”§ Recent Updates (Feb 2026)

### Key Improvements

1. **Simplified Data Alignment** (`utils/data_alignment.py`)
   - Removed timestamp-based alignment (was reducing accuracy)
   - Uses simple index-based pairing for better results
   - Assumes tweets and stock data are pre-aligned in the dataset

2. **Enhanced Model Architectures** (`train.py`)
   - **Bidirectional model optimized for BEST VALIDATION ACCURACY**
   - Added recurrent dropout and L2 regularization to prevent overfitting
   - Batch normalization for stable training
   - Early stopping to prevent overfitting

3. **Individual Model Training**
   - Train specific models with `--model` flag
   - Options: `lstm`, `propose`, `extension`, or `all`

4. **Anti-Overfitting Measures**
   - Early stopping (patience: 20 epochs)
   - Learning rate reduction on plateau
   - Class weights for imbalanced data
   - Strong regularization in all layers

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train Models

Train all models:
```bash
python train.py
```

Train individual models:
```bash
python train.py --model lstm       # Train only LSTM
python train.py --model propose    # Train only LSTM+GRU
python train.py --model extension  # Train only Bidirectional (BEST)
```

Options:
- `--epochs N` - Number of training epochs (default: 100)
- `--batch-size N` - Batch size (default: 32)
- `--model MODEL` - Model to train: lstm, propose, extension, all (default: all)
- `--force-bert` - Recompute BERT embeddings

### 3. Run Dashboard

```bash
streamlit run app.py
```

The dashboard will be available at http://localhost:8501

## ğŸ“ Project Structure

```
Stock-Movement/
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ AAPL.csv          # Stock price data
â”‚   â””â”€â”€ tweets.csv         # Tweet data
â”œâ”€â”€ model/                 # Generated by train.py
â”‚   â”œâ”€â”€ bert.npy          # BERT embeddings
â”‚   â”œâ”€â”€ scaler.pkl        # Fitted scaler (prevents data leakage!)
â”‚   â”œâ”€â”€ lstm_model.h5     # LSTM baseline model
â”‚   â”œâ”€â”€ propose_model.h5  # LSTM+GRU hybrid model
â”‚   â”œâ”€â”€ extension_model.h5 # Bidirectional model (BEST)
â”‚   â”œâ”€â”€ *_history.pckl    # Training histories
â”‚   â”œâ”€â”€ *_weights.hdf5    # Model weights
â”‚   â””â”€â”€ metrics.json      # Performance metrics
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_alignment.py # Dataset alignment utilities
â”‚   â””â”€â”€ preprocessing.py  # Feature engineering utilities
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_utils.py     # Unit tests
â”œâ”€â”€ train.py              # Training pipeline
â”œâ”€â”€ validate_pipeline.py  # Quick validation script
â”œâ”€â”€ app.py                # Streamlit dashboard
â””â”€â”€ README.md             # This file
```

## ğŸ”¬ Technical Details

### Model Architectures

#### 1. LSTM (Baseline)
- 2 LSTM layers (128, 64 units) with batch normalization
- L2 regularization (0.001)
- Progressive dropout (0.3)

#### 2. LSTM + GRU (Propose)
- LSTM layer (128 units) + GRU layers (96, 64 units)
- Batch normalization between layers
- L2 regularization

#### 3. Bidirectional (Extension) - **HIGHEST ACCURACY**
- Bidirectional LSTM layers (96, 64 units)
- Bidirectional GRU layers (48, 32 units)
- **Recurrent dropout** to prevent overfitting
- **L2 regularization** on kernel and recurrent weights
- Progressive dropout (0.2 â†’ 0.5)
- Optimized for **validation accuracy**

### Anti-Overfitting Features

1. **Recurrent Dropout**: Applied within LSTM/GRU cells
2. **L2 Regularization**: On both kernel and recurrent weights
3. **Early Stopping**: Stops when validation accuracy stops improving (patience: 20)
4. **Learning Rate Reduction**: Halves LR when validation loss plateaus
5. **Batch Normalization**: Stabilizes training
6. **Class Weights**: Handles imbalanced data

### Data Alignment

- Uses simple **index-based pairing** (tweets and stock data assumed pre-aligned)
- No timestamp-based alignment (was reducing accuracy)
- Validates required columns in both datasets

### Feature Engineering

1. **Feature Construction**:
   - BERT embeddings: 768 dimensions (tweet sentiment)
   - Stock features: 4 dimensions (Open, High, Low, Close)
   - Combined: 772 dimensions

2. **Preprocessing**:
   - Normalize using MinMaxScaler (fitted on training data only)
   - Skip first 2 features â†’ 770 dimensions
   - Reshape to (35 time steps, 22 features per step)

## ğŸ§ª Testing

Run unit tests:
```bash
python -m pytest tests/ -v
```

## ğŸ“ˆ Performance Metrics

After training, metrics are saved to `model/metrics.json`:
- Accuracy
- Precision
- Recall
- F1 Score

The **extension (Bidirectional) model** typically achieves the highest validation accuracy.

## âš ï¸ Important Notes

1. **Train before running dashboard**: The dashboard requires trained models and scaler
2. **Don't delete scaler.pkl**: Critical for prediction consistency
3. **For educational purposes only**: Not financial advice

## ğŸ“ License

See repository for license information.

## ğŸ™ Credits

- Original implementation: [Pranavvv08](https://github.com/Pranavvv08)
- Technologies: TensorFlow, Keras, Sentence Transformers, Streamlit, Plotly
